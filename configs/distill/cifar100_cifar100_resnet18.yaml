mode: distill

seed: 0
accelerator: cuda
devices: 1
resume: False
wandb: True
tags: [ distillation ]
exp_name: distill_cifar100_cifar100_resnet18
save_dir: distill/cifar100_cifar100/resnet18
workers: 8
save_every: 10
eval_every: 1

model_arch: resnet18_32
num_classes: 100
use_timm: False
pretrained: False
teacher_arch: resnet18_32
teacher_ckpt: pretrained/cifar100/resnet18/last.ckpt

train_dataset: cifar100
test_dataset: cifar100
use_kornia: False

maxepochs: 200
batch_size_train: 128
batch_size_eval: 2048
learning_rate: 0.01
weight_decay: 0.0005
optimizer: 'sgd'
momentum: 0.9
scheduler: 'step'
milestones: [ 60, 120, 160 ]
lr_decay: 0.2

temperature: 8
cutmix: True