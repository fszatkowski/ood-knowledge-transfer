mode: distill

seed: 0
accelerator: cuda
devices: 1
resume: False
wandb: True
tags: [ distillation ]
exp_name: distill_cifar110_cifar10_resnet18
save_dir: distill/cifar110_cifar10/resnet18
workers: 8
save_every: 10
eval_every: 1

model_arch: resnet18_32
num_classes: 10
use_timm: False
pretrained: False
teacher_arch: resnet18_32
teacher_ckpt: pretrained/cifar10/resnet18/last.ckpt

train_dataset: cifar110
test_dataset: cifar10
use_kornia: False

maxepochs: 200
batch_size_train: 128
batch_size_eval: 2048
learning_rate: 0.1
weight_decay: 0.0005
optimizer: 'sgd'
momentum: 0.9
scheduler: 'cosine'

temperature: 2
cutmix: False